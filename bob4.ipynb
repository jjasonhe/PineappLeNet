{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bob4\n",
    "\n",
    "### STATUS\n",
    "\n",
    "#### create_dataset_fcn8\n",
    "- Basically able to return a fuzzy version of the input\n",
    "- Not sure how much more I can tweak the model to reach the next time stamp\n",
    "\n",
    "#### create_dataset_diff\n",
    "- Currently doing **validation data** on both training and evaluation!!\n",
    "- Trying to overfit and show validation function works, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noodles/.conda/envs/turntable/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as wtf\n",
    "import data_utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EPOCHS = 1\n",
    "\n",
    "num_train, num_val, num_test = 70, 10, 20\n",
    "train_data,val_data,test_data = du.create_dicts(num_train, num_val, num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'diff-001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting that FCN8-based model, t->t+1\n",
    "\n",
    "def model_fn(features,\n",
    "             labels,\n",
    "             mode,\n",
    "             params):\n",
    "    with wtf.device('/device:GPU:0'):\n",
    "        inputs = features\n",
    "        \n",
    "        conv1_1 = wtf.layers.conv2d(inputs,\n",
    "                                    filters=64,\n",
    "                                    kernel_size=3,\n",
    "                                    strides=1,\n",
    "                                    padding='same',\n",
    "                                    activation=wtf.nn.relu,\n",
    "                                    kernel_initializer=wtf.variance_scaling_initializer(scale=2.0),\n",
    "                                    name='conv1_1')\n",
    "        conv1_2 = wtf.layers.conv2d(conv1_1,\n",
    "                                    filters=64,\n",
    "                                    kernel_size=3,\n",
    "                                    strides=1,\n",
    "                                    padding='same',\n",
    "                                    activation=wtf.nn.relu,\n",
    "                                    kernel_initializer=wtf.variance_scaling_initializer(scale=2.0),\n",
    "                                    name='conv1_2')\n",
    "        pool1 = wtf.layers.max_pooling2d(conv1_2,\n",
    "                                         pool_size=2,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         name='pool1')\n",
    "        \n",
    "        conv2_1 = wtf.layers.conv2d(pool1,\n",
    "                                    filters=256,\n",
    "                                    kernel_size=3,\n",
    "                                    strides=1,\n",
    "                                    padding='same',\n",
    "                                    activation=wtf.nn.relu,\n",
    "                                    kernel_initializer=wtf.variance_scaling_initializer(scale=2.0),\n",
    "                                    name='conv2_1')\n",
    "        conv2_2 = wtf.layers.conv2d(conv2_1,\n",
    "                                    filters=256,\n",
    "                                    kernel_size=3,\n",
    "                                    strides=1,\n",
    "                                    padding='same',\n",
    "                                    activation=wtf.nn.relu,\n",
    "                                    kernel_initializer=wtf.variance_scaling_initializer(scale=2.0),\n",
    "                                    name='conv2_2')\n",
    "        pool2 = wtf.layers.max_pooling2d(conv2_2,\n",
    "                                         pool_size=2,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         name='pool2')\n",
    "        \n",
    "        conv3_1 = wtf.layers.conv2d(pool2,\n",
    "                                    filters=1024,\n",
    "                                    kernel_size=3,\n",
    "                                    strides=1,\n",
    "                                    padding='same',\n",
    "                                    activation=wtf.nn.relu,\n",
    "                                    kernel_initializer=wtf.variance_scaling_initializer(scale=2.0),\n",
    "                                    name='conv3_1')\n",
    "        conv3_2 = wtf.layers.conv2d(conv3_1,\n",
    "                                    filters=1024,\n",
    "                                    kernel_size=3,\n",
    "                                    strides=1,\n",
    "                                    padding='same',\n",
    "                                    activation=wtf.nn.relu,\n",
    "                                    kernel_initializer=wtf.variance_scaling_initializer(scale=2.0),\n",
    "                                    name='conv3_2')\n",
    "        pool3 = wtf.layers.max_pooling2d(conv3_2,\n",
    "                                         pool_size=2,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         name='pool3')\n",
    "        \n",
    "        conv4_1 = wtf.layers.conv2d(pool3,\n",
    "                                    filters=2048,\n",
    "                                    kernel_size=1,\n",
    "                                    strides=1,\n",
    "                                    padding='same',\n",
    "                                    activation=wtf.nn.relu,\n",
    "                                    kernel_initializer=wtf.variance_scaling_initializer(scale=2.0),\n",
    "                                    name='conv4_1')\n",
    "        \n",
    "        conv4_2 = wtf.layers.conv2d(conv4_1,\n",
    "                                    filters=2048,\n",
    "                                    kernel_size=1,\n",
    "                                    strides=1,\n",
    "                                    padding='same',\n",
    "                                    activation=wtf.nn.relu,\n",
    "                                    kernel_initializer=wtf.variance_scaling_initializer(scale=2.0),\n",
    "                                    name='conv4_2')\n",
    "        \n",
    "        dout = wtf.layers.dropout(conv4_2,\n",
    "                                rate=0.0)\n",
    "        \n",
    "        deconv1 = wtf.layers.conv2d_transpose(dout,\n",
    "                                              filters=pool2.get_shape().as_list()[-1],\n",
    "                                              kernel_size=4,\n",
    "                                              strides=2,\n",
    "                                              padding='same')\n",
    "        \n",
    "        deconv1_skip = wtf.add(deconv1, pool2)\n",
    "        \n",
    "        deconv2 = wtf.layers.conv2d_transpose(deconv1_skip,\n",
    "                                              filters=1,\n",
    "                                              kernel_size=8,\n",
    "                                              strides=4,\n",
    "                                              padding='same')\n",
    "        \n",
    "#         outputs = wtf.add(deconv2, inputs)\n",
    "        outputs = deconv2\n",
    "\n",
    "#         wtf.summary.image('input', inputs, max_outputs=200)\n",
    "#         wtf.summary.image('outputs', outputs, max_outputs=200)\n",
    "#         wtf.summary.image('labels', labels, max_outputs=200)\n",
    "        \n",
    "        # Adds concatenated inputs and outputs to be displayed in TensorBoard\n",
    "        disp = wtf.concat([inputs, labels, outputs], 1)\n",
    "        wtf.summary.image('concat', disp, max_outputs=200)\n",
    "    \n",
    "        predictions = {'results': outputs}\n",
    "    \n",
    "        if mode == wtf.estimator.ModeKeys.PREDICT:\n",
    "            export_outputs = {\n",
    "                'predictions': wtf.estimator.export.PredictOutput(outputs)\n",
    "            }\n",
    "            return wtf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions=outputs\n",
    "            )\n",
    "    \n",
    "        # loss = wtf.losses.mean_squared_error(labels, outputs)\n",
    "        loss = wtf.reduce_sum(wtf.abs(labels - outputs), axis=[1,2,3])\n",
    "        loss = wtf.reduce_mean(loss)\n",
    "        \n",
    "        global_step = wtf.train.get_global_step()\n",
    "        lr = wtf.train.exponential_decay(params.learning_rate, global_step, 1000, 0.96, staircase=True)\n",
    "        \n",
    "        wtf.summary.scalar('learning_rate', lr)\n",
    "        \n",
    "        optimizer = wtf.train.AdamOptimizer(\n",
    "            learning_rate=lr,\n",
    "            beta1=params.beta1,\n",
    "            beta2=params.beta2\n",
    "        )\n",
    "    \n",
    "        update_ops = wtf.get_collection(wtf.GraphKeys.UPDATE_OPS)\n",
    "        with wtf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(\n",
    "                loss=loss, global_step=wtf.train.get_global_step())\n",
    "    \n",
    "        eval_metric_ops = {\n",
    "            \"rmse\": wtf.metrics.root_mean_squared_error(labels, outputs),\n",
    "            \"mae\": wtf.metrics.mean_absolute_error(labels, outputs),\n",
    "            \"mse\": wtf.metrics.mean_squared_error(labels, outputs)\n",
    "        }\n",
    "        \n",
    "        eval_summary_hook = wtf.train.SummarySaverHook(\n",
    "                                save_steps=1,\n",
    "                                output_dir= \"summary/eval/\" + MODEL_NAME,\n",
    "                                scaffold=wtf.train.Scaffold(summary_op=wtf.summary.merge_all()))\n",
    "        \n",
    "        evaluation_hooks=[]\n",
    "        evaluation_hooks.append(eval_summary_hook)\n",
    "    \n",
    "        estimator_spec = wtf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops=eval_metric_ops,\n",
    "            evaluation_hooks=evaluation_hooks\n",
    "        )\n",
    "        \n",
    "        return estimator_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    \n",
    "    wtf.logging.set_verbosity(wtf.logging.INFO)\n",
    "\n",
    "    hparams = wtf.contrib.training.HParams(\n",
    "        #num_epochs=1,\n",
    "        #batch_size = 80,\n",
    "        #forget_bias=1.0,\n",
    "        learning_rate=0.00001,\n",
    "        beta1=0.9,\n",
    "        beta2=0.999\n",
    "    )\n",
    "    \n",
    "    session_config = wtf.ConfigProto()\n",
    "    session_config.gpu_options.allow_growth = True\n",
    "    session_config.allow_soft_placement = True\n",
    "    \n",
    "    run_config = wtf.estimator.RunConfig(\n",
    "        log_step_count_steps=10,\n",
    "        save_summary_steps=10,\n",
    "        tf_random_seed=19830610,\n",
    "        model_dir=os.path.join('summary', 'train', MODEL_NAME),\n",
    "        session_config=session_config\n",
    "    )\n",
    "    \n",
    "    estimator = wtf.estimator.Estimator(\n",
    "        model_fn=model_fn, params=hparams, config=run_config)\n",
    "    \n",
    "#     train_dataset = du.create_dataset('train', train_data)\n",
    "#     train_dataset = du.create_dataset_fcn8('train', train_data)\n",
    "    train_dataset = du.create_dataset_diff('val', val_data)\n",
    "    train_dataset = train_dataset.shuffle(2000)\n",
    "    train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "    train_dataset = train_dataset.repeat(EPOCHS)\n",
    "    \n",
    "    val_dataset = du.create_dataset_diff('val', val_data)\n",
    "    val_dataset = val_dataset.batch(1)\n",
    "    \n",
    "    def train_input_fn():\n",
    "        train_iterator = train_dataset.make_one_shot_iterator()\n",
    "        features, labels = train_iterator.get_next()\n",
    "        return features, labels\n",
    "    \n",
    "    def val_input_fn():\n",
    "        val_iterator = val_dataset.make_one_shot_iterator()\n",
    "        features, labels = val_iterator.get_next()\n",
    "        return features, labels\n",
    "    \n",
    "    estimator.train(input_fn=train_input_fn, max_steps=None)\n",
    "    estimator.evaluate(input_fn=val_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noodles/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'summary/train/diff-001', '_tf_random_seed': 19830610, '_save_summary_steps': 10, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd95b6ba898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into summary/train/diff-001/model.ckpt.\n",
      "INFO:tensorflow:loss = 1165.9114, step = 0\n",
      "INFO:tensorflow:global_step/sec: 1.74834\n",
      "INFO:tensorflow:global_step/sec: 1.82429\n",
      "INFO:tensorflow:global_step/sec: 1.82503\n",
      "INFO:tensorflow:global_step/sec: 1.82461\n",
      "INFO:tensorflow:global_step/sec: 1.82093\n",
      "INFO:tensorflow:global_step/sec: 1.8221\n",
      "INFO:tensorflow:global_step/sec: 1.8217\n",
      "INFO:tensorflow:global_step/sec: 1.82095\n",
      "INFO:tensorflow:global_step/sec: 1.82481\n",
      "INFO:tensorflow:global_step/sec: 1.82006\n",
      "INFO:tensorflow:loss = 545.23474, step = 100 (55.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81932\n",
      "INFO:tensorflow:global_step/sec: 1.81903\n",
      "INFO:tensorflow:global_step/sec: 1.8174\n",
      "INFO:tensorflow:global_step/sec: 1.81823\n",
      "INFO:tensorflow:global_step/sec: 1.81597\n",
      "INFO:tensorflow:global_step/sec: 1.81941\n",
      "INFO:tensorflow:global_step/sec: 1.82161\n",
      "INFO:tensorflow:global_step/sec: 1.81973\n",
      "INFO:tensorflow:global_step/sec: 1.82147\n",
      "INFO:tensorflow:global_step/sec: 1.82164\n",
      "INFO:tensorflow:loss = 654.91705, step = 200 (54.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81706\n",
      "INFO:tensorflow:global_step/sec: 1.82626\n",
      "INFO:tensorflow:global_step/sec: 1.82517\n",
      "INFO:tensorflow:global_step/sec: 1.82065\n",
      "INFO:tensorflow:global_step/sec: 1.81772\n",
      "INFO:tensorflow:global_step/sec: 1.82126\n",
      "INFO:tensorflow:global_step/sec: 1.81974\n",
      "INFO:tensorflow:global_step/sec: 1.81919\n",
      "INFO:tensorflow:global_step/sec: 1.82162\n",
      "INFO:tensorflow:global_step/sec: 1.81908\n",
      "INFO:tensorflow:loss = 755.46643, step = 300 (54.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82323\n",
      "INFO:tensorflow:global_step/sec: 1.82139\n",
      "INFO:tensorflow:global_step/sec: 1.8203\n",
      "INFO:tensorflow:global_step/sec: 1.82182\n",
      "INFO:tensorflow:global_step/sec: 1.82427\n",
      "INFO:tensorflow:global_step/sec: 1.82025\n",
      "INFO:tensorflow:global_step/sec: 1.81976\n",
      "INFO:tensorflow:global_step/sec: 1.82516\n",
      "INFO:tensorflow:global_step/sec: 1.82474\n",
      "INFO:tensorflow:global_step/sec: 1.8232\n",
      "INFO:tensorflow:loss = 294.70483, step = 400 (54.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82766\n",
      "INFO:tensorflow:global_step/sec: 1.82524\n",
      "INFO:tensorflow:global_step/sec: 1.82127\n",
      "INFO:tensorflow:global_step/sec: 1.82466\n",
      "INFO:tensorflow:global_step/sec: 1.82256\n",
      "INFO:tensorflow:global_step/sec: 1.82327\n",
      "INFO:tensorflow:global_step/sec: 1.82908\n",
      "INFO:tensorflow:global_step/sec: 1.82363\n",
      "INFO:tensorflow:global_step/sec: 1.82348\n",
      "INFO:tensorflow:global_step/sec: 1.82287\n",
      "INFO:tensorflow:loss = 351.94577, step = 500 (54.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82678\n",
      "INFO:tensorflow:global_step/sec: 1.82424\n",
      "INFO:tensorflow:global_step/sec: 1.82458\n",
      "INFO:tensorflow:global_step/sec: 1.82261\n",
      "INFO:tensorflow:global_step/sec: 1.82555\n",
      "INFO:tensorflow:global_step/sec: 1.82468\n",
      "INFO:tensorflow:global_step/sec: 1.82092\n",
      "INFO:tensorflow:global_step/sec: 1.82519\n",
      "INFO:tensorflow:global_step/sec: 1.82008\n",
      "INFO:tensorflow:global_step/sec: 1.82436\n",
      "INFO:tensorflow:loss = 581.7848, step = 600 (54.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81931\n",
      "INFO:tensorflow:global_step/sec: 1.8225\n",
      "INFO:tensorflow:global_step/sec: 1.82676\n",
      "INFO:tensorflow:global_step/sec: 1.82314\n",
      "INFO:tensorflow:global_step/sec: 1.82226\n",
      "INFO:tensorflow:global_step/sec: 1.82564\n",
      "INFO:tensorflow:global_step/sec: 1.8224\n",
      "INFO:tensorflow:global_step/sec: 1.82026\n",
      "INFO:tensorflow:global_step/sec: 1.82545\n",
      "INFO:tensorflow:global_step/sec: 1.82466\n",
      "INFO:tensorflow:loss = 565.5543, step = 700 (54.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82046\n",
      "INFO:tensorflow:global_step/sec: 1.82706\n",
      "INFO:tensorflow:global_step/sec: 1.82715\n",
      "INFO:tensorflow:global_step/sec: 1.81867\n",
      "INFO:tensorflow:global_step/sec: 1.82463\n",
      "INFO:tensorflow:global_step/sec: 1.82335\n",
      "INFO:tensorflow:global_step/sec: 1.822\n",
      "INFO:tensorflow:global_step/sec: 1.82344\n",
      "INFO:tensorflow:global_step/sec: 1.82108\n",
      "INFO:tensorflow:global_step/sec: 1.82304\n",
      "INFO:tensorflow:loss = 1162.1404, step = 800 (54.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.81947\n",
      "INFO:tensorflow:global_step/sec: 1.82298\n",
      "INFO:tensorflow:global_step/sec: 1.82061\n",
      "INFO:tensorflow:global_step/sec: 1.82241\n",
      "INFO:tensorflow:global_step/sec: 1.82327\n",
      "INFO:tensorflow:global_step/sec: 1.82245\n",
      "INFO:tensorflow:global_step/sec: 1.82111\n",
      "INFO:tensorflow:global_step/sec: 1.82266\n",
      "INFO:tensorflow:global_step/sec: 1.82027\n",
      "INFO:tensorflow:global_step/sec: 1.82486\n",
      "INFO:tensorflow:loss = 335.82648, step = 900 (54.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82147\n",
      "INFO:tensorflow:global_step/sec: 1.82444\n",
      "INFO:tensorflow:global_step/sec: 1.82086\n",
      "INFO:tensorflow:global_step/sec: 1.82612\n",
      "INFO:tensorflow:global_step/sec: 1.82386\n",
      "INFO:tensorflow:global_step/sec: 1.82232\n",
      "INFO:tensorflow:global_step/sec: 1.8255\n",
      "INFO:tensorflow:global_step/sec: 1.82704\n",
      "INFO:tensorflow:global_step/sec: 1.81901\n",
      "INFO:tensorflow:global_step/sec: 1.82379\n",
      "INFO:tensorflow:loss = 417.80725, step = 1000 (54.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82362\n",
      "INFO:tensorflow:global_step/sec: 1.82396\n",
      "INFO:tensorflow:global_step/sec: 1.82359\n",
      "INFO:tensorflow:global_step/sec: 1.82391\n",
      "INFO:tensorflow:global_step/sec: 1.82026\n",
      "INFO:tensorflow:global_step/sec: 1.81757\n",
      "INFO:tensorflow:global_step/sec: 1.8193\n",
      "INFO:tensorflow:global_step/sec: 1.82082\n",
      "INFO:tensorflow:global_step/sec: 1.81866\n",
      "INFO:tensorflow:Saving checkpoints for 1093 into summary/train/diff-001/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.69601\n",
      "INFO:tensorflow:loss = 294.49432, step = 1100 (55.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82476\n",
      "INFO:tensorflow:global_step/sec: 1.82114\n",
      "INFO:tensorflow:global_step/sec: 1.82191\n",
      "INFO:tensorflow:global_step/sec: 1.82102\n",
      "INFO:tensorflow:global_step/sec: 1.81997\n",
      "INFO:tensorflow:global_step/sec: 1.82282\n",
      "INFO:tensorflow:global_step/sec: 1.82294\n",
      "INFO:tensorflow:global_step/sec: 1.82389\n",
      "INFO:tensorflow:global_step/sec: 1.82058\n",
      "INFO:tensorflow:global_step/sec: 1.82793\n",
      "INFO:tensorflow:loss = 584.0458, step = 1200 (54.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82524\n",
      "INFO:tensorflow:global_step/sec: 1.82243\n",
      "INFO:tensorflow:global_step/sec: 1.8288\n",
      "INFO:tensorflow:global_step/sec: 1.82286\n",
      "INFO:tensorflow:global_step/sec: 1.82401\n",
      "INFO:tensorflow:global_step/sec: 1.8204\n",
      "INFO:tensorflow:global_step/sec: 1.82409\n",
      "INFO:tensorflow:global_step/sec: 1.82473\n",
      "INFO:tensorflow:global_step/sec: 1.82278\n",
      "INFO:tensorflow:global_step/sec: 1.82699\n",
      "INFO:tensorflow:loss = 1000.12146, step = 1300 (54.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82262\n",
      "INFO:tensorflow:global_step/sec: 1.82649\n",
      "INFO:tensorflow:global_step/sec: 1.82663\n",
      "INFO:tensorflow:global_step/sec: 1.82349\n",
      "INFO:tensorflow:global_step/sec: 1.82459\n",
      "INFO:tensorflow:global_step/sec: 1.82093\n",
      "INFO:tensorflow:global_step/sec: 1.81792\n",
      "INFO:tensorflow:global_step/sec: 1.82598\n",
      "INFO:tensorflow:global_step/sec: 1.82878\n",
      "INFO:tensorflow:global_step/sec: 1.82361\n",
      "INFO:tensorflow:loss = 333.69797, step = 1400 (54.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82568\n",
      "INFO:tensorflow:global_step/sec: 1.82701\n",
      "INFO:tensorflow:global_step/sec: 1.82531\n",
      "INFO:tensorflow:global_step/sec: 1.82322\n",
      "INFO:tensorflow:global_step/sec: 1.82439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.82005\n",
      "INFO:tensorflow:global_step/sec: 1.82284\n",
      "INFO:tensorflow:global_step/sec: 1.82246\n",
      "INFO:tensorflow:global_step/sec: 1.82236\n",
      "INFO:tensorflow:global_step/sec: 1.82114\n",
      "INFO:tensorflow:loss = 280.59006, step = 1500 (54.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.82525\n",
      "INFO:tensorflow:global_step/sec: 1.824\n",
      "INFO:tensorflow:global_step/sec: 1.82167\n",
      "INFO:tensorflow:global_step/sec: 1.83097\n",
      "INFO:tensorflow:global_step/sec: 1.82757\n",
      "INFO:tensorflow:global_step/sec: 1.82128\n",
      "INFO:tensorflow:global_step/sec: 1.82377\n",
      "INFO:tensorflow:global_step/sec: 1.82145\n",
      "INFO:tensorflow:global_step/sec: 1.82182\n",
      "INFO:tensorflow:global_step/sec: 1.77393\n",
      "INFO:tensorflow:loss = 297.69516, step = 1600 (54.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.76321\n",
      "INFO:tensorflow:global_step/sec: 1.74832\n",
      "INFO:tensorflow:global_step/sec: 1.7487\n",
      "INFO:tensorflow:global_step/sec: 1.745\n",
      "INFO:tensorflow:global_step/sec: 1.74549\n",
      "INFO:tensorflow:global_step/sec: 1.7728\n",
      "INFO:tensorflow:global_step/sec: 1.76412\n",
      "INFO:tensorflow:global_step/sec: 1.75845\n",
      "INFO:tensorflow:global_step/sec: 1.75878\n",
      "INFO:tensorflow:global_step/sec: 1.73778\n",
      "INFO:tensorflow:loss = 552.79816, step = 1700 (57.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.74513\n",
      "INFO:tensorflow:global_step/sec: 1.75482\n",
      "INFO:tensorflow:global_step/sec: 1.76683\n",
      "INFO:tensorflow:global_step/sec: 1.78223\n",
      "INFO:tensorflow:global_step/sec: 1.76503\n",
      "INFO:tensorflow:global_step/sec: 1.74888\n",
      "INFO:tensorflow:global_step/sec: 1.76847\n",
      "INFO:tensorflow:global_step/sec: 1.74\n",
      "INFO:tensorflow:global_step/sec: 1.77042\n",
      "INFO:tensorflow:global_step/sec: 1.74984\n",
      "INFO:tensorflow:loss = 514.12164, step = 1800 (56.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.75043\n",
      "INFO:tensorflow:global_step/sec: 1.73648\n",
      "INFO:tensorflow:global_step/sec: 1.77128\n",
      "INFO:tensorflow:global_step/sec: 1.7859\n",
      "INFO:tensorflow:global_step/sec: 1.75369\n",
      "INFO:tensorflow:global_step/sec: 1.76063\n",
      "INFO:tensorflow:global_step/sec: 1.7709\n",
      "INFO:tensorflow:global_step/sec: 1.76175\n",
      "INFO:tensorflow:global_step/sec: 1.76028\n",
      "INFO:tensorflow:global_step/sec: 1.75822\n",
      "INFO:tensorflow:loss = 731.0011, step = 1900 (56.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.76881\n",
      "INFO:tensorflow:global_step/sec: 1.74992\n",
      "INFO:tensorflow:global_step/sec: 1.75638\n",
      "INFO:tensorflow:global_step/sec: 1.77462\n",
      "INFO:tensorflow:global_step/sec: 1.76316\n",
      "INFO:tensorflow:global_step/sec: 1.79837\n",
      "INFO:tensorflow:global_step/sec: 1.75911\n",
      "INFO:tensorflow:global_step/sec: 1.76191\n",
      "INFO:tensorflow:global_step/sec: 1.7587\n",
      "INFO:tensorflow:global_step/sec: 1.76978\n",
      "INFO:tensorflow:loss = 355.5089, step = 2000 (56.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.75172\n",
      "INFO:tensorflow:global_step/sec: 1.7808\n",
      "INFO:tensorflow:global_step/sec: 1.78112\n",
      "INFO:tensorflow:global_step/sec: 1.76334\n",
      "INFO:tensorflow:global_step/sec: 1.76429\n",
      "INFO:tensorflow:global_step/sec: 1.7594\n",
      "INFO:tensorflow:global_step/sec: 1.76151\n",
      "INFO:tensorflow:global_step/sec: 1.778\n",
      "INFO:tensorflow:global_step/sec: 1.76235\n",
      "INFO:tensorflow:global_step/sec: 1.7622\n",
      "INFO:tensorflow:loss = 698.23895, step = 2100 (56.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77291\n",
      "INFO:tensorflow:global_step/sec: 1.77273\n",
      "INFO:tensorflow:global_step/sec: 1.76225\n",
      "INFO:tensorflow:global_step/sec: 1.74509\n",
      "INFO:tensorflow:global_step/sec: 1.76762\n",
      "INFO:tensorflow:global_step/sec: 1.77228\n",
      "INFO:tensorflow:Saving checkpoints for 2167 into summary/train/diff-001/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.63064\n",
      "INFO:tensorflow:global_step/sec: 1.78088\n",
      "INFO:tensorflow:global_step/sec: 1.77283\n",
      "INFO:tensorflow:global_step/sec: 1.73792\n",
      "INFO:tensorflow:loss = 412.60373, step = 2200 (57.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.75279\n",
      "INFO:tensorflow:global_step/sec: 1.74774\n",
      "INFO:tensorflow:global_step/sec: 1.59297\n",
      "INFO:tensorflow:global_step/sec: 1.78574\n",
      "INFO:tensorflow:global_step/sec: 1.76841\n",
      "INFO:tensorflow:global_step/sec: 1.74779\n",
      "INFO:tensorflow:global_step/sec: 1.7643\n",
      "INFO:tensorflow:global_step/sec: 1.74818\n",
      "INFO:tensorflow:global_step/sec: 1.75408\n",
      "INFO:tensorflow:global_step/sec: 1.78123\n",
      "INFO:tensorflow:loss = 413.96884, step = 2300 (57.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.76414\n",
      "INFO:tensorflow:global_step/sec: 1.77766\n",
      "INFO:tensorflow:global_step/sec: 1.77641\n",
      "INFO:tensorflow:global_step/sec: 1.78232\n",
      "INFO:tensorflow:global_step/sec: 1.76807\n",
      "INFO:tensorflow:global_step/sec: 1.77364\n",
      "INFO:tensorflow:global_step/sec: 1.7496\n",
      "INFO:tensorflow:global_step/sec: 1.75088\n",
      "INFO:tensorflow:global_step/sec: 1.76332\n",
      "INFO:tensorflow:global_step/sec: 1.75967\n",
      "INFO:tensorflow:loss = 565.65234, step = 2400 (56.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.77326\n",
      "INFO:tensorflow:global_step/sec: 1.74925\n",
      "INFO:tensorflow:global_step/sec: 1.78283\n",
      "INFO:tensorflow:global_step/sec: 1.75155\n",
      "INFO:tensorflow:global_step/sec: 1.782\n",
      "INFO:tensorflow:global_step/sec: 1.76759\n",
      "INFO:tensorflow:global_step/sec: 1.76541\n",
      "INFO:tensorflow:global_step/sec: 1.72313\n",
      "INFO:tensorflow:global_step/sec: 1.75303\n",
      "INFO:tensorflow:global_step/sec: 1.76013\n",
      "INFO:tensorflow:loss = 221.44148, step = 2500 (56.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.76533\n",
      "INFO:tensorflow:global_step/sec: 1.77256\n",
      "INFO:tensorflow:global_step/sec: 1.7331\n",
      "INFO:tensorflow:global_step/sec: 1.7533\n",
      "INFO:tensorflow:global_step/sec: 1.74675\n",
      "INFO:tensorflow:global_step/sec: 1.77102\n",
      "INFO:tensorflow:global_step/sec: 1.76973\n",
      "INFO:tensorflow:global_step/sec: 1.75591\n",
      "INFO:tensorflow:global_step/sec: 1.76733\n",
      "INFO:tensorflow:global_step/sec: 1.77264\n",
      "INFO:tensorflow:loss = 307.05072, step = 2600 (56.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.75364\n",
      "INFO:tensorflow:global_step/sec: 1.72601\n",
      "INFO:tensorflow:global_step/sec: 1.76007\n",
      "INFO:tensorflow:global_step/sec: 1.75342\n",
      "INFO:tensorflow:global_step/sec: 1.75278\n",
      "INFO:tensorflow:global_step/sec: 1.74754\n",
      "INFO:tensorflow:global_step/sec: 1.74318\n",
      "INFO:tensorflow:global_step/sec: 1.74537\n",
      "INFO:tensorflow:global_step/sec: 1.78739\n",
      "INFO:tensorflow:global_step/sec: 1.84223\n",
      "INFO:tensorflow:loss = 253.55055, step = 2700 (56.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.8376\n",
      "INFO:tensorflow:global_step/sec: 1.84216\n",
      "INFO:tensorflow:global_step/sec: 1.83997\n",
      "INFO:tensorflow:global_step/sec: 1.83889\n",
      "INFO:tensorflow:global_step/sec: 1.83628\n",
      "INFO:tensorflow:global_step/sec: 1.84245\n",
      "INFO:tensorflow:global_step/sec: 1.83964\n",
      "INFO:tensorflow:global_step/sec: 1.83903\n",
      "INFO:tensorflow:global_step/sec: 1.8427\n",
      "INFO:tensorflow:global_step/sec: 1.83739\n",
      "INFO:tensorflow:loss = 269.0224, step = 2800 (54.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.84093\n",
      "INFO:tensorflow:global_step/sec: 1.83956\n",
      "INFO:tensorflow:global_step/sec: 1.84015\n",
      "INFO:tensorflow:global_step/sec: 1.8351\n",
      "INFO:tensorflow:global_step/sec: 1.84435\n",
      "INFO:tensorflow:global_step/sec: 1.83689\n",
      "INFO:tensorflow:global_step/sec: 1.8407\n",
      "INFO:tensorflow:global_step/sec: 1.83827\n",
      "INFO:tensorflow:global_step/sec: 1.83883\n",
      "INFO:tensorflow:global_step/sec: 1.83902\n",
      "INFO:tensorflow:loss = 566.43225, step = 2900 (54.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83901\n",
      "INFO:tensorflow:global_step/sec: 1.84458\n",
      "INFO:tensorflow:global_step/sec: 1.84075\n",
      "INFO:tensorflow:global_step/sec: 1.83567\n",
      "INFO:tensorflow:global_step/sec: 1.84438\n",
      "INFO:tensorflow:global_step/sec: 1.8415\n",
      "INFO:tensorflow:global_step/sec: 1.83726\n",
      "INFO:tensorflow:global_step/sec: 1.84317\n",
      "INFO:tensorflow:global_step/sec: 1.84158\n",
      "INFO:tensorflow:global_step/sec: 1.83456\n",
      "INFO:tensorflow:loss = 389.94196, step = 3000 (54.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.843\n",
      "INFO:tensorflow:global_step/sec: 1.84223\n",
      "INFO:tensorflow:global_step/sec: 1.83913\n",
      "INFO:tensorflow:global_step/sec: 1.83923\n",
      "INFO:tensorflow:global_step/sec: 1.84145\n",
      "INFO:tensorflow:global_step/sec: 1.83844\n",
      "INFO:tensorflow:global_step/sec: 1.83617\n",
      "INFO:tensorflow:global_step/sec: 1.8411\n",
      "INFO:tensorflow:global_step/sec: 1.84188\n",
      "INFO:tensorflow:global_step/sec: 1.83979\n",
      "INFO:tensorflow:loss = 164.71002, step = 3100 (54.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.83853\n",
      "INFO:tensorflow:global_step/sec: 1.84006\n",
      "INFO:tensorflow:global_step/sec: 1.84367\n",
      "INFO:tensorflow:global_step/sec: 1.84256\n",
      "INFO:tensorflow:global_step/sec: 1.83856\n",
      "INFO:tensorflow:global_step/sec: 1.8415\n",
      "INFO:tensorflow:global_step/sec: 1.83868\n",
      "INFO:tensorflow:global_step/sec: 1.83856\n",
      "INFO:tensorflow:Saving checkpoints for 3188 into summary/train/diff-001/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 521.2726.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-03-07:25:15\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from summary/train/diff-001/model.ckpt-3188\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    wtf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
