{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v1nyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noodles/.conda/envs/turntable/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noodles/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import h5py as h5\n",
    "import data_utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_step(slices):\n",
    "\tnum_slice,_,_,_ = slices.shape\n",
    "\tprint(num_slice)\n",
    "\tslices = slices.transpose(0,2,1,3)\n",
    "#\tslices = tf.transpose(slices, perm=[0,2,1,3])\n",
    "#\tprint(slices.dtype)\n",
    "\tfor s in range(num_slice):\n",
    "\t\tfig = plt.figure(s)\n",
    "\t\t# a = plt.subplot(num_slice, 1, 1+s)\n",
    "\t\tplt.imshow(np.abs(slices[s,:,:,0]), cmap='gray')\n",
    "#\t\tprint(slices[s,:,:,0].dtype.base_dtype)\n",
    "# \t\tplt.imshow(slices[s,:,:,0], cmap='gray')\n",
    "#\t\tplt.imshow(slices[s,:,:,0])\n",
    "\t\tplt.title(\"%d\" % s)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_train, num_val, num_test = 70, 10, 20\n",
    "\n",
    "train_data,val_data,test_data = du.create_dicts(num_train, num_val, num_test)\n",
    "maxX,maxY,maxT = du.init() # call once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creates h5 files of the data, each patient is a dataset\n",
    "# du.train_h5(train_data, maxX, maxY, maxT)\n",
    "# du.val_h5(val_data, maxX, maxY, maxT)\n",
    "# du.test_h5(test_data, maxX, maxY, maxT)\n",
    "\n",
    "# Creates tfrecords files where data is sorted slice-by-slice, in chunks of (T,H,W,C)\n",
    "# du.what_tf('train', train_data)\n",
    "# du.what_tf('val', val_data)\n",
    "# du.what_tf('test', test_data)\n",
    "\n",
    "# Creates tfrecords files where data is sorted image-by-image, in chunks of (H,W,C)\n",
    "# du.what_tf_fcn8('train', train_data)\n",
    "# du.what_tf_fcn8('val', val_data)\n",
    "# du.what_tf_fcn8('test', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fc = h5.File('datasets/train_curr.h5', 'r')\n",
    "# fn = h5.File('datasets/train_next.h5', 'r')\n",
    "# print(fc[train_data[0]].shape)\n",
    "# print(fn[train_data[0]].shape)\n",
    "# plot_time_step(fc[train_data[0]][510], fn[train_data[0]][510])\n",
    "f = h5.File('datasets/train.h5', 'r')\n",
    "print(f[train_data[0]].shape)\n",
    "print(f[train_data[0]].dtype)\n",
    "plot_time_step(f[train_data[0]][25,1:18,:,:,:])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'model-002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMCell(tf.nn.rnn_cell.RNNCell):\n",
    "  \"\"\"A LSTM cell with convolutions instead of multiplications.\n",
    "  Reference:\n",
    "    Xingjian, S. H. I., et al. \"Convolutional LSTM network: A machine learning approach for precipitation nowcasting.\" Advances in Neural Information Processing Systems. 2015.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, shape, filters, kernel, forget_bias=1.0, activation=tf.tanh, normalize=True, peephole=True, data_format='channels_last', reuse=None):\n",
    "    super(ConvLSTMCell, self).__init__(_reuse=reuse)\n",
    "    self._kernel = kernel\n",
    "    self._filters = filters\n",
    "    self._forget_bias = forget_bias\n",
    "    self._activation = activation\n",
    "    self._normalize = normalize\n",
    "    self._peephole = peephole\n",
    "    if data_format == 'channels_last':\n",
    "        self._size = tf.TensorShape(shape + [self._filters])\n",
    "        self._feature_axis = self._size.ndims\n",
    "        self._data_format = None\n",
    "    elif data_format == 'channels_first':\n",
    "        self._size = tf.TensorShape([self._filters] + shape)\n",
    "        self._feature_axis = 0\n",
    "        self._data_format = 'NC'\n",
    "    else:\n",
    "        raise ValueError('Unknown data_format')\n",
    "\n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return tf.nn.rnn_cell.LSTMStateTuple(self._size, self._size)\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self._size\n",
    "\n",
    "  def call(self, x, state):\n",
    "    c, h = state\n",
    "\n",
    "    x = tf.concat([x, h], axis=self._feature_axis)\n",
    "    n = x.shape[-1].value\n",
    "    m = 4 * self._filters if self._filters > 1 else 4\n",
    "    W = tf.get_variable('kernel', self._kernel + [n, m])\n",
    "    y = tf.nn.convolution(x, W, 'SAME', data_format=self._data_format)\n",
    "    if not self._normalize:\n",
    "      y += tf.get_variable('bias', [m], initializer=tf.zeros_initializer())\n",
    "    j, i, f, o = tf.split(y, 4, axis=self._feature_axis)\n",
    "\n",
    "    if self._peephole:\n",
    "      i += tf.get_variable('W_ci', c.shape[1:]) * c\n",
    "      f += tf.get_variable('W_cf', c.shape[1:]) * c\n",
    "\n",
    "    if self._normalize:\n",
    "      j = tf.contrib.layers.layer_norm(j)\n",
    "      i = tf.contrib.layers.layer_norm(i)\n",
    "      f = tf.contrib.layers.layer_norm(f)\n",
    "\n",
    "    f = tf.sigmoid(f + self._forget_bias)\n",
    "    i = tf.sigmoid(i)\n",
    "    c = c * f + i * self._activation(j)\n",
    "\n",
    "    if self._peephole:\n",
    "      o += tf.get_variable('W_co', c.shape[1:]) * c\n",
    "\n",
    "    if self._normalize:\n",
    "      o = tf.contrib.layers.layer_norm(o)\n",
    "      c = tf.contrib.layers.layer_norm(c)\n",
    "\n",
    "    o = tf.sigmoid(o)\n",
    "    h = o * self._activation(c)\n",
    "\n",
    "    state = tf.nn.rnn_cell.LSTMStateTuple(c, h)\n",
    "\n",
    "    return h, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial ConvLSTM-based model\n",
    "\n",
    "def model_fn(features,\n",
    "             labels,\n",
    "             mode,\n",
    "             params):\n",
    "    with tf.device('/device:GPU:0'):\n",
    "    \n",
    "        img_curr = features\n",
    "        img_next = labels\n",
    "    \n",
    "        inputs = img_curr\n",
    "    \n",
    "        #tf.summary.image('input', inputs[0,:,:,:,:], max_outputs=200)\n",
    "    \n",
    "        #print(inputs.get_shape())\n",
    "    \n",
    "        #inputs = tf.split(value=img_curr, num_or_size_splits=17)\n",
    "        #print('inputs={}'.format(inputs))\n",
    "    \n",
    "        convlstm_cell = rnn.Conv2DLSTMCell(\n",
    "            input_shape=[224, 192, 1],\n",
    "            output_channels=1,\n",
    "            kernel_shape=[5,5],\n",
    "            use_bias=True,\n",
    "            skip_connection=False,\n",
    "            forget_bias=params.forget_bias\n",
    "        )\n",
    "    \n",
    "        outputs, _ = tf.nn.dynamic_rnn(\n",
    "            cell=convlstm_cell,\n",
    "            inputs=inputs,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "    \n",
    "        print('outputs={}'.format(outputs))\n",
    "    \n",
    "        # Adds output predictions to be displayed in TensorBoard\n",
    "        #tf.summary.image('output', outputs[0,:,:,:,:], max_outputs=200)\n",
    "    \n",
    "        disp = tf.concat([inputs[0,:,:,:,:], outputs[0,:,:,:,:]], 1)\n",
    "        tf.summary.image('concat', disp, max_outputs=200)\n",
    "    \n",
    "        predictions = {'results': outputs}\n",
    "    \n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            export_outputs = {\n",
    "                'predictions': tf.estimator.export.PredictOutput(outputs)\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions=outputs\n",
    "            )\n",
    "    \n",
    "        loss = tf.losses.mean_squared_error(img_next, outputs)\n",
    "    \n",
    "        optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=params.learning_rate,\n",
    "            beta1=params.beta1,\n",
    "            beta2=params.beta2,\n",
    "            epsilon=params.epsilon\n",
    "        )\n",
    "    \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(\n",
    "                loss=loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "        eval_metric_ops = {\n",
    "            \"rmse\": tf.metrics.root_mean_squared_error(img_next, outputs),\n",
    "            \"mae\": tf.metrics.mean_absolute_error(img_next, outputs),\n",
    "            \"mse\": tf.metrics.mean_squared_error(img_next, outputs)\n",
    "        }\n",
    "    \n",
    "        estimator_spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops=eval_metric_ops\n",
    "        )\n",
    "        \n",
    "        return estimator_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model function using just a single conv-deconv\n",
    "\n",
    "def model_fn(features,\n",
    "             labels,\n",
    "             mode,\n",
    "             params):\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        inputs = features\n",
    "        \n",
    "        conv_out = tf.layers.conv2d(inputs, filters=32, kernel_size=5, strides=1, padding='same')\n",
    "        \n",
    "        outputs = tf.layers.conv2d_transpose(conv_out, filters=1, kernel_size=5, strides=1, padding='same')\n",
    "    \n",
    "        # Adds output predictions to be displayed in TensorBoard\n",
    "        #tf.summary.image('output', outputs[0,:,:,:,:], max_outputs=200)\n",
    "        \n",
    "        # Adds concatenated inputs and outputs to be displayed in TensorBoard\n",
    "        disp = tf.concat([inputs[:,:,:], outputs[:,:,:]], 1)\n",
    "        tf.summary.image('concat', disp, max_outputs=200)\n",
    "    \n",
    "        predictions = {'results': outputs}\n",
    "    \n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            export_outputs = {\n",
    "                'predictions': tf.estimator.export.PredictOutput(outputs)\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions=outputs\n",
    "            )\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            disp = tf.concat([inputs[:,:,:], outputs[:,:,:]], 1)\n",
    "            tf.summary.image('concat', disp, max_outputs=200)\n",
    "    \n",
    "        loss = tf.losses.mean_squared_error(labels, outputs)\n",
    "    \n",
    "        optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=params.learning_rate,\n",
    "            beta1=params.beta1,\n",
    "            beta2=params.beta2,\n",
    "            epsilon=params.epsilon\n",
    "        )\n",
    "    \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(\n",
    "                loss=loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "        eval_metric_ops = {\n",
    "            \"rmse\": tf.metrics.root_mean_squared_error(labels, outputs),\n",
    "            \"mae\": tf.metrics.mean_absolute_error(labels, outputs),\n",
    "            \"mse\": tf.metrics.mean_squared_error(labels, outputs)\n",
    "        }\n",
    "    \n",
    "        estimator_spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops=eval_metric_ops\n",
    "        )\n",
    "        \n",
    "        return estimator_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting that FCN8-based model, t->t+1\n",
    "\n",
    "def model_fn(features,\n",
    "             labels,\n",
    "             mode,\n",
    "             params):\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        inputs = features\n",
    "        \n",
    "#         vgg16_model = tf.keras.applications.VGG16(include_top=false,\n",
    "#                                                   weights='imagenet',\n",
    "#                                                   input_tensor=inputs,\n",
    "#                                                   input_shape=(192,224,1))\n",
    "        \n",
    "        with tf.name_scope('conv1_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 1, 64], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(inputs, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            conv1_1 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "        with tf.name_scope('conv1_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 64], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(conv1_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            conv1_2 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "        #pool1 = tf.layers.max_pooling2d(conv1_2, pool_size=2, strides=2, padding='SAME')\n",
    "        \n",
    "        pool1 = tf.nn.max_pool(conv1_2,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool1')\n",
    "        \n",
    "        with tf.name_scope('conv2_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 128], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            conv2_1 = tf.nn.relu(out, name=scope)\n",
    "            \n",
    "        with tf.name_scope('conv2_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 128], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(conv2_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            conv2_2 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "        pool2 = tf.nn.max_pool(conv2_2,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool2')\n",
    "        \n",
    "        with tf.name_scope('conv3_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(pool2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            conv3_1 = tf.nn.relu(out, name=scope)\n",
    "            \n",
    "        with tf.name_scope('conv3_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(conv3_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            conv3_2 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "        with tf.name_scope('conv3_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(conv3_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            conv3_3 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "        pool3 = tf.nn.max_pool(conv3_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool3')\n",
    "        \n",
    "        with tf.name_scope('conv4_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(pool3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            conv4_1 = tf.nn.relu(out, name=scope)\n",
    "            \n",
    "        with tf.name_scope('conv4_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(conv4_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            conv4_2 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "        with tf.name_scope('conv4_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(conv4_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            conv4_3 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "        pool4 = tf.nn.max_pool(conv4_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool4')\n",
    "        \n",
    "        with tf.name_scope('conv5_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(pool4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            conv5_1 = tf.nn.relu(out, name=scope)\n",
    "            \n",
    "        with tf.name_scope('conv5_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(conv5_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            conv5_2 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "        with tf.name_scope('conv5_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(conv5_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            conv5_3 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "        pool5 = tf.nn.max_pool(conv5_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool5')\n",
    "        \n",
    "        with tf.name_scope('fc1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([1, 1, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(pool5, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            fc1 = tf.nn.relu(out, name=scope)\n",
    "            \n",
    "        with tf.name_scope('fc2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([1, 1, 512, 4096], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(fc1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[4096], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            fc2 = tf.nn.relu(out, name=scope)\n",
    "        \n",
    "#         with tf.name_scope('fc2') as scope:\n",
    "#             fc2w = tf.Variable(tf.truncated_normal([4096, 4096],\n",
    "#                                                    dtype=tf.float32,\n",
    "#                                                    stddev=1e-1), name='weights')\n",
    "#             fc2b = tf.Variable(tf.constant(1.0, shape=[4096], dtype=tf.float32),\n",
    "#                                trainable=True, name='biases')\n",
    "#             fc2l = tf.nn.bias_add(tf.matmul(fc1, fc2w), fc2b)\n",
    "#             fc2 = tf.nn.relu(fc2l)\n",
    "        \n",
    "#         with tf.name_scope('fc3') as scope:\n",
    "#             fc3w = tf.Variable(tf.truncated_normal([4096, 1000],\n",
    "#                                                    dtype=tf.float32,\n",
    "#                                                    stddev=1e-1), name='weights')\n",
    "#             fc3b = tf.Variable(tf.constant(1.0, shape=[1000], dtype=tf.float32),\n",
    "#                                trainable=True, name='biases')\n",
    "#             fc3l = tf.nn.bias_add(tf.matmul(fc2, fc3w), fc3b)\n",
    "#             fc3 = tf.nn.relu(fc3l)\n",
    "        \n",
    "        fcn8 = tf.layers.conv2d(fc2, filters=1000, kernel_size = 1)\n",
    "        fcn9 = tf.layers.conv2d_transpose(fcn8, filters=pool4.get_shape().as_list()[-1],\n",
    "                                          kernel_size=4, strides=2, padding='SAME')\n",
    "        fcn9_skip = tf.add(fcn9, pool4)\n",
    "        fcn10= tf.layers.conv2d_transpose(fcn9_skip, filters=pool3.get_shape().as_list()[-1],\n",
    "                                          kernel_size=4, strides=2, padding='SAME')\n",
    "        fcn10_skip= tf.add(fcn10, pool3)\n",
    "        outputs = tf.layers.conv2d_transpose(fcn10_skip, filters=1,\n",
    "                                             kernel_size=16, strides=8, padding='SAME')\n",
    "        \n",
    "        # Adds concatenated inputs and outputs to be displayed in TensorBoard\n",
    "        disp = tf.concat([inputs[:,:,:], outputs[:,:,:]], 1)\n",
    "        tf.summary.image('concat', disp, max_outputs=200)\n",
    "    \n",
    "        predictions = {'results': outputs}\n",
    "    \n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            export_outputs = {\n",
    "                'predictions': tf.estimator.export.PredictOutput(outputs)\n",
    "            }\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions=outputs\n",
    "            )\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            disp = tf.concat([inputs[:,:,:], outputs[:,:,:]], 1)\n",
    "            tf.summary.image('concat', disp, max_outputs=200)\n",
    "    \n",
    "        loss = tf.losses.mean_squared_error(labels, outputs)\n",
    "    \n",
    "        optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=params.learning_rate,\n",
    "            beta1=params.beta1,\n",
    "            beta2=params.beta2,\n",
    "            epsilon=params.epsilon\n",
    "        )\n",
    "    \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(\n",
    "                loss=loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "        eval_metric_ops = {\n",
    "            \"rmse\": tf.metrics.root_mean_squared_error(labels, outputs),\n",
    "            \"mae\": tf.metrics.mean_absolute_error(labels, outputs),\n",
    "            \"mse\": tf.metrics.mean_squared_error(labels, outputs)\n",
    "        }\n",
    "    \n",
    "        estimator_spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops=eval_metric_ops\n",
    "        )\n",
    "        \n",
    "        return estimator_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    \n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    hparams = tf.contrib.training.HParams(\n",
    "        #num_epochs=1,\n",
    "        #batch_size = 80,\n",
    "        #forget_bias=1.0,\n",
    "        learning_rate=0.001,\n",
    "        beta1=0.9,\n",
    "        beta2=0.999,\n",
    "        epsilon=1,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    session_config = tf.ConfigProto()\n",
    "    session_config.gpu_options.allow_growth = True\n",
    "    session_config.allow_soft_placement = True\n",
    "    \n",
    "    run_config = tf.estimator.RunConfig(\n",
    "        log_step_count_steps=10,\n",
    "        save_summary_steps=10,\n",
    "        tf_random_seed=19830610,\n",
    "        model_dir=os.path.join('summary', 'train', MODEL_NAME),\n",
    "        session_config=session_config\n",
    "    )\n",
    "    \n",
    "    estimator = tf.estimator.Estimator(\n",
    "        model_fn=model_fn, params=hparams, config=run_config)\n",
    "    \n",
    "#     train_dataset = du.create_dataset('train', train_data)\n",
    "    train_dataset = du.create_dataset_fcn8('train', train_data)\n",
    "    train_dataset = train_dataset.shuffle(2000)\n",
    "    train_dataset = train_dataset.batch(50)\n",
    "    train_dataset = train_dataset.repeat(4)\n",
    "    \n",
    "#     val_dataset = du.create_dataset_fcn8('val', val_data)\n",
    "#     val_dataset = val_dataset.batch(35)\n",
    "\n",
    "#     print(train_dataset.output_types)\n",
    "#     print(train_dataset.output_shapes)\n",
    "#     print(val_dataset.output_types)\n",
    "#     print(val_dataset.output_shapes)\n",
    "    \n",
    "    def train_input_fn():\n",
    "        train_iterator = train_dataset.make_one_shot_iterator()\n",
    "        features, labels = train_iterator.get_next()\n",
    "        return features, labels\n",
    "    \n",
    "    def val_input_fn():\n",
    "        val_iterator = val_dataset.make_one_shot_iterator()\n",
    "        features, labels = val_iterator.get_next()\n",
    "        return features, labels\n",
    "    \n",
    "    estimator.train(input_fn=train_input_fn, max_steps=None)\n",
    "#     estimator.evaluate(input_fn=val_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'summary/train/model-002', '_tf_random_seed': 19830610, '_save_summary_steps': 10, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f26482e32b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from summary/train/model-002/model.ckpt-1824\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1825 into summary/train/model-002/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.4221463, step = 1824\n",
      "INFO:tensorflow:global_step/sec: 0.618548\n",
      "INFO:tensorflow:global_step/sec: 0.635103\n",
      "INFO:tensorflow:global_step/sec: 0.581642\n",
      "INFO:tensorflow:global_step/sec: 0.625068\n",
      "INFO:tensorflow:global_step/sec: 0.613792\n",
      "INFO:tensorflow:global_step/sec: 0.622421\n",
      "INFO:tensorflow:global_step/sec: 0.61662\n",
      "INFO:tensorflow:global_step/sec: 0.613782\n",
      "INFO:tensorflow:global_step/sec: 0.624922\n",
      "INFO:tensorflow:global_step/sec: 0.618984\n",
      "INFO:tensorflow:loss = 0.3503706, step = 1924 (162.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.62019\n",
      "INFO:tensorflow:global_step/sec: 0.622518\n",
      "INFO:tensorflow:global_step/sec: 0.620117\n",
      "INFO:tensorflow:global_step/sec: 0.618247\n",
      "INFO:tensorflow:global_step/sec: 0.624691\n",
      "INFO:tensorflow:global_step/sec: 0.618664\n",
      "INFO:tensorflow:global_step/sec: 0.61225\n",
      "INFO:tensorflow:global_step/sec: 0.606583\n",
      "INFO:tensorflow:global_step/sec: 0.615028\n",
      "INFO:tensorflow:global_step/sec: 0.627654\n",
      "INFO:tensorflow:loss = 0.30003908, step = 2024 (161.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.626259\n",
      "INFO:tensorflow:global_step/sec: 0.6158\n",
      "INFO:tensorflow:global_step/sec: 0.631975\n",
      "INFO:tensorflow:global_step/sec: 0.633248\n",
      "INFO:tensorflow:global_step/sec: 0.631818\n",
      "INFO:tensorflow:global_step/sec: 0.623559\n",
      "INFO:tensorflow:global_step/sec: 0.614199\n",
      "INFO:tensorflow:global_step/sec: 0.632017\n",
      "INFO:tensorflow:global_step/sec: 0.625038\n",
      "INFO:tensorflow:global_step/sec: 0.631331\n",
      "INFO:tensorflow:loss = 0.256323, step = 2124 (159.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.622109\n",
      "INFO:tensorflow:global_step/sec: 0.624132\n",
      "INFO:tensorflow:global_step/sec: 0.626391\n",
      "INFO:tensorflow:global_step/sec: 0.629895\n",
      "INFO:tensorflow:global_step/sec: 0.619746\n",
      "INFO:tensorflow:global_step/sec: 0.621668\n",
      "INFO:tensorflow:global_step/sec: 0.627676\n",
      "INFO:tensorflow:Saving checkpoints for 2198 into summary/train/model-002/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.568151\n",
      "INFO:tensorflow:global_step/sec: 0.622816\n",
      "INFO:tensorflow:global_step/sec: 0.619706\n",
      "INFO:tensorflow:loss = 0.29205936, step = 2224 (161.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.634282\n",
      "INFO:tensorflow:global_step/sec: 0.616895\n",
      "INFO:tensorflow:global_step/sec: 0.617885\n",
      "INFO:tensorflow:global_step/sec: 0.625938\n",
      "INFO:tensorflow:global_step/sec: 0.626324\n",
      "INFO:tensorflow:global_step/sec: 0.633016\n",
      "INFO:tensorflow:global_step/sec: 0.632753\n",
      "INFO:tensorflow:global_step/sec: 0.620338\n",
      "INFO:tensorflow:global_step/sec: 0.617736\n",
      "INFO:tensorflow:global_step/sec: 0.616406\n",
      "INFO:tensorflow:loss = 0.21628635, step = 2324 (160.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.622065\n",
      "INFO:tensorflow:global_step/sec: 0.625146\n",
      "INFO:tensorflow:global_step/sec: 0.624374\n",
      "INFO:tensorflow:global_step/sec: 0.617827\n",
      "INFO:tensorflow:global_step/sec: 0.616073\n",
      "INFO:tensorflow:global_step/sec: 0.615048\n",
      "INFO:tensorflow:global_step/sec: 0.624809\n",
      "INFO:tensorflow:global_step/sec: 0.605476\n",
      "INFO:tensorflow:global_step/sec: 0.622344\n",
      "INFO:tensorflow:global_step/sec: 0.618468\n",
      "INFO:tensorflow:loss = 0.19536304, step = 2424 (161.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.636675\n",
      "INFO:tensorflow:global_step/sec: 0.63176\n",
      "INFO:tensorflow:global_step/sec: 0.619291\n",
      "INFO:tensorflow:global_step/sec: 0.630698\n",
      "INFO:tensorflow:global_step/sec: 0.62447\n",
      "INFO:tensorflow:global_step/sec: 0.632792\n",
      "INFO:tensorflow:global_step/sec: 0.62336\n",
      "INFO:tensorflow:global_step/sec: 0.615873\n",
      "INFO:tensorflow:global_step/sec: 0.631694\n",
      "INFO:tensorflow:global_step/sec: 0.631904\n",
      "INFO:tensorflow:loss = 0.22235939, step = 2524 (159.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.638964\n",
      "INFO:tensorflow:global_step/sec: 0.630776\n",
      "INFO:tensorflow:global_step/sec: 0.637491\n",
      "INFO:tensorflow:global_step/sec: 0.622317\n",
      "INFO:tensorflow:Saving checkpoints for 2572 into summary/train/model-002/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.607655\n",
      "INFO:tensorflow:global_step/sec: 0.639087\n",
      "INFO:tensorflow:global_step/sec: 0.59645\n",
      "INFO:tensorflow:global_step/sec: 0.614312\n",
      "INFO:tensorflow:global_step/sec: 0.632678\n",
      "INFO:tensorflow:global_step/sec: 0.635306\n",
      "INFO:tensorflow:loss = 0.21050476, step = 2624 (159.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.636982\n",
      "INFO:tensorflow:global_step/sec: 0.628432\n",
      "INFO:tensorflow:global_step/sec: 0.621006\n",
      "INFO:tensorflow:global_step/sec: 0.633811\n",
      "INFO:tensorflow:global_step/sec: 0.632283\n",
      "INFO:tensorflow:global_step/sec: 0.637528\n",
      "INFO:tensorflow:global_step/sec: 0.625012\n",
      "INFO:tensorflow:global_step/sec: 0.627846\n",
      "INFO:tensorflow:global_step/sec: 0.628136\n",
      "INFO:tensorflow:global_step/sec: 0.629508\n",
      "INFO:tensorflow:loss = 0.21218704, step = 2724 (158.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.632058\n",
      "INFO:tensorflow:global_step/sec: 0.615861\n",
      "INFO:tensorflow:global_step/sec: 0.634822\n",
      "INFO:tensorflow:global_step/sec: 0.622514\n",
      "INFO:tensorflow:global_step/sec: 0.627541\n",
      "INFO:tensorflow:global_step/sec: 0.628105\n",
      "INFO:tensorflow:global_step/sec: 0.631089\n",
      "INFO:tensorflow:global_step/sec: 0.629863\n",
      "INFO:tensorflow:global_step/sec: 0.631164\n",
      "INFO:tensorflow:global_step/sec: 0.625482\n",
      "INFO:tensorflow:loss = 0.17909776, step = 2824 (159.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.627492\n",
      "INFO:tensorflow:global_step/sec: 0.623451\n",
      "INFO:tensorflow:global_step/sec: 0.633008\n",
      "INFO:tensorflow:global_step/sec: 0.633597\n",
      "INFO:tensorflow:global_step/sec: 0.631327\n",
      "INFO:tensorflow:global_step/sec: 0.625116\n",
      "INFO:tensorflow:global_step/sec: 0.629067\n",
      "INFO:tensorflow:global_step/sec: 0.630371\n",
      "INFO:tensorflow:global_step/sec: 0.616776\n",
      "INFO:tensorflow:global_step/sec: 0.623821\n",
      "INFO:tensorflow:loss = 0.15218121, step = 2924 (159.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.620715\n",
      "INFO:tensorflow:global_step/sec: 0.619258\n",
      "INFO:tensorflow:Saving checkpoints for 2948 into summary/train/model-002/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.611072\n",
      "INFO:tensorflow:global_step/sec: 0.583959\n",
      "INFO:tensorflow:global_step/sec: 0.641423\n",
      "INFO:tensorflow:global_step/sec: 0.632748\n",
      "INFO:tensorflow:global_step/sec: 0.627358\n",
      "INFO:tensorflow:global_step/sec: 0.624286\n",
      "INFO:tensorflow:global_step/sec: 0.626346\n",
      "INFO:tensorflow:global_step/sec: 0.630987\n",
      "INFO:tensorflow:loss = 0.16085641, step = 3024 (160.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.636941\n",
      "INFO:tensorflow:global_step/sec: 0.630824\n",
      "INFO:tensorflow:global_step/sec: 0.625722\n",
      "INFO:tensorflow:global_step/sec: 0.620006\n",
      "INFO:tensorflow:global_step/sec: 0.634071\n",
      "INFO:tensorflow:global_step/sec: 0.635744\n",
      "INFO:tensorflow:global_step/sec: 0.631168\n",
      "INFO:tensorflow:global_step/sec: 0.628537\n",
      "INFO:tensorflow:global_step/sec: 0.631912\n",
      "INFO:tensorflow:global_step/sec: 0.629855\n",
      "INFO:tensorflow:loss = 0.17432888, step = 3124 (158.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.626828\n",
      "INFO:tensorflow:global_step/sec: 0.62921\n",
      "INFO:tensorflow:global_step/sec: 0.630578\n",
      "INFO:tensorflow:global_step/sec: 0.630462\n",
      "INFO:tensorflow:global_step/sec: 0.627245\n",
      "INFO:tensorflow:global_step/sec: 0.628548\n",
      "INFO:tensorflow:global_step/sec: 0.625264\n",
      "INFO:tensorflow:global_step/sec: 0.629679\n",
      "INFO:tensorflow:global_step/sec: 0.638945\n",
      "INFO:tensorflow:global_step/sec: 0.640005\n",
      "INFO:tensorflow:loss = 0.120693885, step = 3224 (158.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.62596\n",
      "INFO:tensorflow:Saving checkpoints for 3325 into summary/train/model-002/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.615665\n",
      "INFO:tensorflow:loss = 0.18223953, step = 3324 (159.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.641808\n",
      "INFO:tensorflow:global_step/sec: 0.631894\n",
      "INFO:tensorflow:global_step/sec: 0.594339\n",
      "INFO:tensorflow:global_step/sec: 0.626441\n",
      "INFO:tensorflow:global_step/sec: 0.634713\n",
      "INFO:tensorflow:global_step/sec: 0.638701\n",
      "INFO:tensorflow:global_step/sec: 0.634186\n",
      "INFO:tensorflow:global_step/sec: 0.618441\n",
      "INFO:tensorflow:global_step/sec: 0.634015\n",
      "INFO:tensorflow:global_step/sec: 0.625739\n",
      "INFO:tensorflow:loss = 0.10195224, step = 3424 (159.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.63086\n",
      "INFO:tensorflow:global_step/sec: 0.632786\n",
      "INFO:tensorflow:global_step/sec: 0.626491\n",
      "INFO:tensorflow:global_step/sec: 0.629897\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cf34dbe789c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6246fd527e75>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;31m#     estimator.evaluate(input_fn=val_input_fn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    544\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1023\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/turntable/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
